{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><b>Public AI</b></i>\n",
    "<br>\n",
    "###  &nbsp;&nbsp; **✎&nbsp;&nbsp;Week 2. Convolution Neural Network**\n",
    "# Section 3. Fully Convolutional Network Classification\n",
    "\n",
    "\n",
    "### _Objective_\n",
    "1. **Fully Convolutional Network** 을 이해하고 구현해 봅니다.\n",
    "2. **Fashion MNIST Classification 만들기** : Keras를 FCN Classification Model 을 구현합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If You use in Colab, You Should run this script\n",
    "import os\n",
    "if (not os.path.exists(\"./multicampus_segmentation_generator\") and\n",
    "    not \"multicampus_segmentation_generator\" in os.getcwd()):\n",
    "    !git clone https://github.com/public-ai/multicampus_segmentation_generator.git\n",
    "    os.chdir(\"./multicampus_segmentation_generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rgT5LzKgdmW1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Conv2D, MaxPool2D, Conv2DTranspose, ZeroPadding2D\n",
    "from tensorflow.keras.layers import Input, UpSampling2D, BatchNormalization, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import Softmax, Add\n",
    "from tensorflow.keras.layers import Lambda, concatenate\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow.keras.backend as K \n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "from generator import fasion_mnist_generator\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 논문 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imgur](https://i.imgur.com/HEHu5TU.png)\n",
    "- Referece: Fully Convolutional Networks for Semantic Segmentation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fully Convolutional Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fully Connected Layer(Dense) 연결시 Image 크기를 고정해야 하는 단점이 있습니다. <br>\n",
    " 반면 Convolution Neural Network 은 이미지 사이즈에 제한을 받지 않습니다. \n",
    "    \n",
    " Image 크기에 Network 제한을 받지 않지 않도록 기존의 **Dense Layer** 를 **Convolution Neural Network** 로 바꿔 봅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Fashion Mnist  Dataset 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fashion mnist 가져오기\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalization\n",
    "train_images = train_images / 255.\n",
    "test_images = test_images / 255.\n",
    "\n",
    "# exapnd Dimension\n",
    "train_images = np.expand_dims(train_images, axis=-1)\n",
    "test_images = np.expand_dims(test_images, axis=-1)\n",
    "print('Train Images Max: {}, Min: {}, \\nTest Images Max: {}, Min: {}'.format(train_images.max(),\n",
    "                                                                           train_images.min(),\n",
    "                                                                           test_images.max(),\n",
    "                                                                           test_images.min()))\n",
    "print('Train Images Shape {} , Test Images Shape : {}'.format(train_images.shape, test_images.shape))\n",
    "\n",
    "\n",
    "# label - name \n",
    "label2name={0: 'T-shirt/top', 1:'Trouser', 2:'Pullover', 3:'Dress', 4:'Coat', 5:'Sandal', 6:'Shirt', 7:'Sneaker', 8:'Bag', 9:'Ankle boot'}\n",
    "\n",
    "\n",
    "# labels to onehot vector \n",
    "n_classes = 10\n",
    "train_labels = np_utils.to_categorical(train_labels, n_classes)\n",
    "test_labels = np_utils.to_categorical(test_labels, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  (Review) Classification Model with Convolution Network + FC Model 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "# fix me! # input과 class 갯수 n_classes를 설정해주세요\n",
    "\n",
    "# Build Models\n",
    "# Conv Block 1, Image shape (28, 28) -> (14, 14)\n",
    "# filter 갯수 : 16개 // filter 크기 : (5,5), padding : same, kernel initializer : he_normal\n",
    "# 위 조건들에 맞게 Convolution Neural Network를 구성해주세요\n",
    "# fix me!\n",
    "\n",
    "\n",
    "# Conv Block 2 Output Shape : (14, 14) -> (7, 7)\n",
    "# filter 갯수 : 32개 // filter 크기 : (3,3), padding : same, kernel initializer : he_normal\n",
    "# 위 조건들에 맞게 Convolution Neural Network를 구성해주세요\n",
    "# fix me!\n",
    "\n",
    "\n",
    "# Conv Block 3 Output Shape :(7, 7) -> (4, 4)\n",
    "# filter 갯수 : 64개 // filter 크기 : (3,3), padding : same, kernel initializer : he_normal\n",
    "# 위 조건들에 맞게 Convolution Neural Network를 구성해주세요\n",
    "# fix me!\n",
    "\n",
    "\n",
    "# Flatten\n",
    "# fix me!\n",
    "\n",
    "# Logits Layer\n",
    "# fix me\n",
    "\n",
    "# Model \n",
    "# fix me! # 모델을 생성해주세요\n",
    "\n",
    "# Compile\n",
    "# fix me! # optimizer로는 'adam'을, metric으로는 'acc'를 사용해주세요,\n",
    "\n",
    "# Fitting\n",
    "# fix me! batch size는 64, epochs=100, validation_split은 0.2로 학습을 진행해주세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCN 구현하기 \n",
    " - Dense Layer 을 Convolution 으로 변경합니다. \n",
    " - Label 의 Shape 을 변경해줍니다. (N, N_classes) ->  (N, 1, 1, N_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "# fix me! # input과 class 갯수 n_classes를 설정해주세요\n",
    "\n",
    "# Build Models\n",
    "# Conv Block 1, Image shape (28, 28) -> (14, 14)\n",
    "# filter 갯수 : 16개 // filter 크기 : (5,5), padding : same, kernel initializer : he_normal\n",
    "# 위 조건들에 맞게 Convolution Neural Network를 구성해주세요\n",
    "# fix me!\n",
    "\n",
    "\n",
    "# Conv Block 2 Output Shape : (14, 14) -> (7, 7)\n",
    "# filter 갯수 : 32개 // filter 크기 : (3,3), padding : same, kernel initializer : he_normal\n",
    "# 위 조건들에 맞게 Convolution Neural Network를 구성해주세요\n",
    "# fix me!\n",
    "\n",
    "\n",
    "# Conv Block 3 Output Shape :(7, 7) -> (4, 4)\n",
    "# filter 갯수 : 64개 // filter 크기 : (3,3), padding : same, kernel initializer : he_normal\n",
    "# 위 조건들에 맞게 Convolution Neural Network를 구성해주세요\n",
    "# fix me!\n",
    "\n",
    "\n",
    "# Flatten\n",
    "# fix me!\n",
    "\n",
    "# Logits Layer\n",
    "# fix me\n",
    "\n",
    "# Model \n",
    "# fix me! # 모델을 생성해주세요\n",
    "\n",
    "# Compile\n",
    "# fix me! # optimizer로는 'adam'을, metric으로는 'acc'를 사용해주세요,\n",
    "\n",
    "# Reshape labels\n",
    "# fix me!# model의 출력 결과를 잘 생각해보고 label을 reshape해주세요\n",
    "\n",
    "# Fitting\n",
    "# fix me! batch size는 64, epochs=100, validation_split은 0.2로 학습을 진행해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wsMjhC-dOm_e"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(test_images)\n",
    "pred_cls = np.argmax(np.squeeze(pred), axis=-1)\n",
    "y_cls = np.argmax(np.squeeze(train_labels), axis=-1)\n",
    "print('shape {} => {}'.format(pred.shape, pred_cls.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AEHwqU9cosUF"
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_images[0, :, :, 0])\n",
    "print('True: {} , Predict: {}'.format(label2name[pred_cls[0]], label2name[y_cls[0,]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "⊙ Copyright(c) 2020 by PublicAI. All rights reserved <br>\n",
    "All pictures, codes, writings cannot be copied without permission. <br>\n",
    "Writen by PAI(info@publicai.co.kr) <br>\n",
    "last updated on 2020/01/4 <br>\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "FCN_8_by_paper_ConvTranspose.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
