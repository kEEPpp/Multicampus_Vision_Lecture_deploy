{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><b>Public AI</b></i>\n",
    "<br>\n",
    "\n",
    "###  &nbsp;&nbsp; **✎&nbsp;&nbsp;Week 9. CNN Basis**\n",
    "# Section 6. CNN 모델 설계 시 고려사항\n",
    "\n",
    "### _Objective_\n",
    "1. CNN 모델을 설계할 때에는 한 픽셀 당 얼마만큼의 범위를 처리하고 있는지를 설명하는 Receptive Field의 크기를 계산하는 법을 배웁니다. <br>\n",
    "2. CNN 모델이 학습 시 얼마만큼의 Memory가 필요한지를 배웁니다. <br>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# \\[ 1. Receptive Field란? \\]\n",
    "\n",
    "----\n",
    "----\n",
    " \n",
    "> *Receptive Field는 Input Space에서 얼마 만큼을 계산해 포함했는지에 대한 지표입니다.*<br>\n",
    "> *Receptive Field가 넓을수록, 더 많은 범위의 정보를 활용해 결과를 계산합니다.*<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. 단일 층일 때의 Receptive Field\n",
    "---\n",
    "\n",
    "단일 층일 때의 Receptive Field는 Filter의 크기와 동일합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Filter Size가 3일 때의 Receptive Field\n",
    "![Imgur](https://i.imgur.com/ZCMV3DE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Filter Size가 5일 때의 Receptive Field\n",
    "![Imgur](https://i.imgur.com/VUlDmQX.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## 2. 복수 층일 때의 Receptive Field\n",
    "---\n",
    "\n",
    "복수 층일 경우, stride에 따라 Receptive Field가 크게 달라집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) stride가 1일때의 Receptive Field\n",
    "![Imgur](https://i.imgur.com/6Wxe00G.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Stride가 2일때의 Receptive Field\n",
    "![Imgur](https://i.imgur.com/dB8vpmv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 3층에서의 Recpetive Field\n",
    "![Imgur](https://i.imgur.com/Gy6Sp2F.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3. Receptive Field 계산법\n",
    "---\n",
    "\n",
    "Receptive Field를 계산하기 위해서는 아래의 재귀식을 통해 계산할 수 있습니다.<br>\n",
    "\n",
    "$\n",
    "r^{[l]} = r^{[l-1]} + (k-1)\\times j_{[l-1]} \\\\\n",
    "j^{[l]} = j^{[l-1]} \\times s^{[l]}\\\\\n",
    "------\\\\\n",
    "r^{[l]} \\mbox{ : receptive field size} \\\\\n",
    "j^{[l]} \\mbox{ : distance between two points } \\\\\n",
    "s^{[l]} \\mbox{ : convolution stride size}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 4. Fully Connected Layer와 Convolution Layer의 비교\n",
    "---\n",
    "* 모든 Fully Connected Layer은 Convolution Layer로 바꿀 수 있습니다.<br>\n",
    "* Fully Connected layer는 Filter Size가 Input size와 동일한 Convolution layer와 동일합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Fully Connected Layer와 Convolution Layer의 구조도\n",
    "\n",
    "두 모델은 아래와 같이 도식화할 수 있습니다.\n",
    "\n",
    "![Imgur](https://i.imgur.com/VGRC6Bf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution Layer의 Filter 크기가 Input Size와 동일하다면, 아래와 같게 됩니다.<br>\n",
    "\n",
    "![Imgur](https://i.imgur.com/xLLnDhJ.png)\n",
    "\n",
    "이는 Fully Connected Layer와 Convolution Layer가 사실상 동일한 연산으로 동작합니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 후 많은 모델들이 이러한 특성을 착안해 Fully Convolutional Network,<br>\n",
    "convolution layer로만 이루어진 모델로 여러 컴퓨터 비전 Task들을 수행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# \\[ 2. CNN 모델의 Memory 요구사항 \\]\n",
    "\n",
    "----\n",
    "----\n",
    "\n",
    "> *Convolution Neural Network는 Parameter Sharing을 통해, Parameter의 수를 획기적으로 줄였지만, 학습할 때에는 매우 많은 메모리를 요구합니다.*<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. CNN 모델을 학습할 때 메모리가 많이 필요한 이유\n",
    "---\n",
    "\n",
    "* CNN 모델을 학습할 때에는 많은 메모리를 잡아먹습니다.<br>\n",
    "* CNN 의 sparse 특성은 computer 는\n",
    "* CNN 모델을 학습할 때 대용량의 GPU 머신이 필요한 이유이기도 합니다.<br>\n",
    "* 역전파의 수식을 통해 그 이유를 파악해보도록 하겠습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Weight에 대한 Gradient Descent \n",
    "\n",
    "가중치들은 아래의 방식으로 학습됩니다.<br>\n",
    "$W_{new} = W_{old} - \\alpha*\\frac{\\partial L}{\\partial W}$<br>\n",
    "\n",
    "우리는 위에서 각 가중치들의 기울기인 $\\frac{\\partial L}{\\partial W}$을 구하기 위해서는 <br>\n",
    "각 층으로 들어온 입력 값($x$)를 기억해야 합니다.\n",
    "\n",
    "![Imgur](https://i.imgur.com/TTi1Mey.png)\n",
    "\n",
    "훈련하는 동안에는 Feed Forward로 계산되었던 모든 값이 Back Propagation을 위해<br>\n",
    "기억해야 합니다. 그래서 적어도 각 층의 계산에서 이용되었던 RAM 양의 전체 합만큼이 필요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. 필요 메모리 크기 계산하기\n",
    "---\n",
    "\n",
    "LeNet-5에서 이용하는 메모리의 크기를 통해 필요 메모리를 계산해보도록 하겠습니다.<br>\n",
    "\n",
    "![Imgur](https://i.imgur.com/WCN9wTP.png)\n",
    "\n",
    "\n",
    "| 층  | 종류 |필터 갯수 | 필터 크기 | 스트라이드 | 패딩 |\n",
    "|--- |--- | ----|   ----|----|----|\n",
    "| c1 |합성곱| 6   | (5,5) | 1  | valid |\n",
    "| s2 |pooling| --- | (2,2) | 2  | valid | \n",
    "| c3 |합성곱| 16  | (10,10) | 1 | valid |\n",
    "| s4 |pooling| --- | (2,2) | 2 | valid |\n",
    "| c5 |합성곱 | 120  | (5,5) | 1  | valid |\n",
    "| f6 |FC   | 84   | --- | ---  | --- |\n",
    "| OUT | softmax | 10 |  --- | --- | --- |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 전체 파라미터 수 계산하기\n",
    "각 층별로 필요한 파라미터 수를 계산하면 다음과 같습니다.\n",
    "\n",
    "| Layer | # Weight | # Bias | # Parameter |\n",
    "| ----- | ------- | ------- | ------- | \n",
    "|  C1   | $(5*5*1*6)=150$|$6$| $150+6=156 $ |\n",
    "|  S2   | $0$ | $0$ | $0$ |\n",
    "|  C3   | $(5*5*6*16)=2400$|$16$|$2400+16=2416 $ |\n",
    "|  S4   | $0$ | $0$ | $0$ |\n",
    "|  C5   | $(5*5*16*120)=48000$|$120$| $48000+120=48,120$ |\n",
    "|  F6   | $120*84 = 10,080 $ | $84$ | $ 10,080+84=10164 $\n",
    "|OUTPUT | $84*10 = 840$ | $10$| $840+10=850$ |\n",
    "\n",
    "총 파라미터의 수는 61,706개입니다. <br>\n",
    "각 파라미터 별로 4바이트씩 가진다고 하면, **239KB**정도의 메모리 공간을 차지 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 각 층 별 출력 값의 크기 계산하기\n",
    "각 층별 출력 크기는 아래와 같습니다.\n",
    "\n",
    "| Layer | FEATURE MAP SHAPE | Total size |\n",
    "| ----- | -------   | -------   | \n",
    "| INPUT | (32,32,1) | 1024 |\n",
    "|  C1   | (28,28,6) | 4704 |\n",
    "|  S2   | (14,14,6) | 1176 |\n",
    "|  C3   | (10,10,16) | 1600 |\n",
    "|  S4   | (5,5,16) | 400 |\n",
    "|  C5   | (1,1,120)| 120 |\n",
    "|  F6   | (84,) | 84 | \n",
    "|  OUTPUT   | (10,) | 10 |\n",
    "\n",
    "총 출력 값의 크기는 9118개입니다.<br>\n",
    "각 출력 값별로 4바이트씩 가진다고 하면, **36KB**정도의 메모리 공간을 차지합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 배치 단위 적용하기\n",
    "\n",
    "실제로 학습을 할 때에는 1개의 데이터가 아닌 복수개의 데이터를 한번에 연산합니다.<br>\n",
    "배치 단위로 처리하기 때문에, 실제로 필수 메모리를 계산할 때에는 출력 값의 크기에 <br>\n",
    "배치 크기를 곱해 계산해야 합니다.\n",
    "\n",
    "배치 단위가 100일때의 필요 메모리 크기 :<br>\n",
    "$\n",
    "\\mbox{total memory size } = \\mbox{parameter size} + \\mbox{batch size} * \\mbox{feedforward memory size} \\\\\n",
    "= 239 + 100 *36 = 3839KB\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LENET-5와 같이 Input Size가 작은 모델에서는 Memory가 큰 이슈가 되지 않습니다.<br>\n",
    "하지만 이후 배울 alex net, vggnet, resnet는 수 Gigabytes의 메모리를 필요로 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) 큰 이미지에서의 메모리 요구사항\n",
    "\n",
    "ImageNet은 가장 유명한 컴퓨터 비전 데이터셋 중 하나입니다.<br>\n",
    "\n",
    "![Imgur](https://i.imgur.com/VCT8bo7.png)\n",
    "\n",
    "위의 데이터 셋을 처리하는 모델들은 보통 (224,224,3)의 크기로 줄이거나 crop해서 이용합니다.<br>\n",
    "\n",
    "아래의 조건으로 구성된 Convolution Layer가 있습니다.<br>\n",
    "* filter 갯수 : 256\n",
    "* filter 크기 : (5,5)\n",
    "* stride : 1\n",
    "* padding : SAME\n",
    "\n",
    "이 층의 출력 값의 크기는 얼마나 될까요? <br>\n",
    "* output size : $(256,256,256) = 256^3 = 2^{24}$\n",
    "\n",
    "총 배치가 100 개가 있다면, 차지하는 메모리는 아래와 같습니다.<br>\n",
    "* memory size : batch size $\\times$ output size $\\times$ 4bytes\n",
    "= $100 \\times 2^{24} \\times 4$ = 6.25GB\n",
    "\n",
    "보통 큰 단일 GPU 머신이 12GB임을 미루어볼때, CNN은 많은 메모리를 소모하는 것을 <br>\n",
    "알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5625"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25*2**24*4/1024/1024/1024 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) 메모리를 줄이는 방법, pooling과 Stride\n",
    "\n",
    "위와 같이 메모리가 가장 많이 먹는 이유 중 하나는 바로, **출력의 크기**에 있습니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "⊙ Copyright(c) 2020 by PublicAI. All rights reserved <br>\n",
    "All pictures, codes, writings cannot be copied without permission. <br>\n",
    "Writen by PAI(info@publicai.co.kr) <br>\n",
    "last updated on 2020/01/4 <br>\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
