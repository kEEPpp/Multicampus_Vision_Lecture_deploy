{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bCx5BXUfno3b"
   },
   "source": [
    "<i><b>Public AI</b></i>\n",
    "<br>\n",
    "\n",
    "###  &nbsp;&nbsp; **✎&nbsp;&nbsp;Week 2. CNN Basis**\n",
    "# Section 5. 5_합성곱_신경망의_층 구성하기\n",
    "\n",
    "### _Objective_\n",
    "1. 합성곱 층은 이전에 배운 DNN와 비슷하게, Logit을 계산하는 부분과 활성화 함수를 계산하는 부분으로 나누어집니다. <br>\n",
    "2. 고전 CNN 모델을 살펴보면서, CNN의 구조에 대해 배워보도록 하겠습니다.  <br> \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6lVIf6B-no3d"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "57fjO_Vgno3f"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "# \\[ 1. 합성곱 층의 구조 \\]\n",
    "\n",
    "----\n",
    "----\n",
    " \n",
    "> *합성곱 연산도 이전의 Fully Connected Layed와 마찬가지로, Bias가 존재합니다.*<br>\n",
    "> *합성곱 연산 이후 활성화 함수를 넣음으로써, 비선형성을 증대시킵니다.*<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c9lI9zvPno3g"
   },
   "source": [
    "## 1. 합성곱 연산에 Bias 추가하기\n",
    "---\n",
    "\n",
    "* 각 필터 별로 Bias를 추가함으로써, 필터 별 Threshold을 학습할 수 있게 됩니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NRk7XJrKno3g"
   },
   "source": [
    "### (1) 3차원 데이터 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Jt2ocRlpno3h",
    "outputId": "956711af-c005-4c21-ddb8-a541a89f7577"
   },
   "outputs": [],
   "source": [
    "in0 = np.array([\n",
    "    [1,4,2,0],\n",
    "    [2,3,1,1],\n",
    "    [3,1,3,2],\n",
    "    [4,2,1,4],\n",
    "])\n",
    "in1 = np.array([\n",
    "    [1,7,0,2],\n",
    "    [3,2,1,1],\n",
    "    [0,7,5,1],\n",
    "    [0,1,5,2],    \n",
    "])\n",
    "in2 = np.array([\n",
    "    [1,5,1,5],\n",
    "    [3,2,1,9],\n",
    "    [4,2,2,7],\n",
    "    [1,2,1,9],\n",
    "])\n",
    "inputs = np.stack([in0, in1, in2],axis=-1)\n",
    "print(\"입력값의 형태 (H, W, C) :({},{},{})\".format(*inputs.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0rYUyRdno3l"
   },
   "source": [
    "### (2) Filter 와 Bias 구성하기\n",
    "* 하나의 유닛당 하나의 bias 가 존재 합니다. \n",
    "\n",
    "* filter 는 하나의 유닛이라 생각할 수 있습니다. 즉 bias 는 filter 의 갯수만큼 생성됩니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "foe3ax4qno3m",
    "outputId": "9602c989-92cd-45c2-f106-f008db36d1f2"
   },
   "outputs": [],
   "source": [
    "filter_1 = np.array([\n",
    "    [[2,0,1],[0,1,2],[1,0,2]],\n",
    "    [[0,1,3],[2,1,3],[4,1,2]],\n",
    "    [[3,2,1],[2,2,3],[0,0,1]]])\n",
    "filter_2 = np.array([\n",
    "    [[4,0,1],[0,0,4],[0,3,2]],\n",
    "    [[6,1,2],[3,5,1],[2,3,2]],\n",
    "    [[1,4,1],[1,3,1],[2,1,0]]])\n",
    "\n",
    "filters = np.stack([filter_1,filter_2],axis=0)\n",
    "print(\"Filter의 형태 (N, H, W, C) : ({},{},{},{})\".format(*filters.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cpREXfakno3o",
    "outputId": "1b7fc867-1c94-48f0-e971-262b574d3b7d"
   },
   "outputs": [],
   "source": [
    "bias = np.array([-100,20])\n",
    "print(\"bias의 갯수 : {}\".format(len(bias)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YsjPfKC-no3r"
   },
   "source": [
    "### (3) 합성곱 연산 진행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "colab_type": "code",
    "id": "fXhz9xEYno3s",
    "outputId": "bd2a8f8c-614d-4267-9d7e-9d1e4d2ceb88"
   },
   "outputs": [],
   "source": [
    "# 합성곱 연산 진행하기\n",
    "outputs = np.zeros([2,2,2])\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        for k in range(2):\n",
    "            result = np.sum(inputs[i:i+3,j:j+3,k] * filters[k])\n",
    "            outputs[i,j,k] = result\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "colab_type": "code",
    "id": "8JCOzvg3no3w",
    "outputId": "862eb966-8e30-468a-d47a-993a713997ee"
   },
   "outputs": [],
   "source": [
    "# bias를 더해줌\n",
    "outputs = outputs + bias \n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bLYJwlwLno3z"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 2. 합성곱 연산 후 활성화함수 추가하기\n",
    "---\n",
    "\n",
    "* 이전의 DNN 구조와 동일하게 합성곱을 거친 후, 활성화함수를 거침으로써,<br>\n",
    "보다 복잡한 특징들을 추출할 수 있게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lm8ure5ino30"
   },
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(x,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "colab_type": "code",
    "id": "jMXzlHUWno32",
    "outputId": "674fff9b-09bb-4b87-f7a8-14576dd88096"
   },
   "outputs": [],
   "source": [
    "# 활성화 함수를 거침\n",
    "a = relu(outputs)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_JNC1LQhno34"
   },
   "source": [
    "합성곱 신경망의 한 계층은 DNN과 같이 두단계를 거칩니다.<br>\n",
    "1. 합성곱 연산(with bias)\n",
    "2. 활성화 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pYj-55Z0no36"
   },
   "source": [
    "<br>\n",
    "\n",
    "## 3. 합성곱 층의 Notation\n",
    "---\n",
    "\n",
    "* 이후 논문과 모델 구조를 보면서 빠르게 이해할 수 있도록, 주요 Notation을 정리하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oBIdCF7Lno37"
   },
   "source": [
    "$\n",
    "f^{[l]} = \\mbox{filter size} \\\\\n",
    "p^{[l]} = \\mbox{padding} \\\\\n",
    "s^{[l]} = \\mbox{stride} \\\\\n",
    "k^{[l]} = \\mbox{number of filters}\\\\\n",
    "----\\\\\n",
    "\\mbox{input shape : } (n_h^{[l-1]},n_w^{[l-1]},n_c^{[l-1]}) \\\\\n",
    "\\mbox{filter shape : } ( f^{[l]}_h,f^{[l]}_w,n_c^{[l-1]},k^{[l]}) \\\\\n",
    "\\mbox{output shape : } (n_h^{[l]},n_w^{[l]},n_c^{[l]})\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dsDm5Ibyno37"
   },
   "source": [
    "### (1) 출력 층의 크기 (output shape)\n",
    "\n",
    "출력 층의 높이와 폭은 아래의 수식 구조를 따릅니다.\n",
    "\n",
    "$\n",
    "n_h^{[l]} = \\lfloor \\frac{n_h^{[l-1]}+2p^{[l]}-f_h^{[l]}}{s^{[l]}}+1\\rfloor\n",
    "$<br>\n",
    "$\n",
    "n_w^{[l]} = \\lfloor \\frac{n_w^{[l-1]}+2p^{[l]}-f_h^{[l]}}{s^{[l]}}+1\\rfloor\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U5BJ9ZJlno38"
   },
   "source": [
    "### (2) 출력 값의 채널 수\n",
    "\n",
    "출력 층의 채널의 수($n_c^{[l]}$)는 필터의 갯수($k^{[l]}$)와 동일합니다.\n",
    "\n",
    "$\n",
    "n_c^{[l]} = k^{[l]}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xUNV9Hunno38"
   },
   "source": [
    "### (3) 파라미터의 수 \n",
    "\n",
    "각 합성곱 층은 Filter 내 Weight와 Bias로 이루어져 있습니다.<br>\n",
    "$\n",
    "\\mbox{# parameter} = \\mbox{#weights} + \\mbox{#bias} \\\\\n",
    "\\mbox{# weights} = f_h^{[l]} * f_w^{[l]} * n_c^{l-1} * k^{[l]} \\\\\n",
    "\\mbox{# bias} = n_c^{[l]}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZHYjFNTmno39"
   },
   "source": [
    "<br><br>\n",
    "\n",
    "# \\[ 2. CNN 모델 분석하기 \\]\n",
    "\n",
    "----\n",
    "----\n",
    " \n",
    "> *고전 모델 중 하나인 LeNet-5을 각 단계별로 출력 값의 크기 및 파라미터의 수를 계산해보도록 하겠습니다.*<br>\n",
    "\n",
    "\n",
    "간단한 CNN 모델의 구성을 통해 계산해보기\n",
    "----\n",
    "![Imgur](https://i.imgur.com/DHpS6r8.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w76KPf8zno39"
   },
   "source": [
    "각 층 별 필터의 크기, 스트라이드, 패딩은 아래와 같습니다.\n",
    "\n",
    "| Layer | # filters | filter size | stride | padding |\n",
    "| ----- | -------   | ------ | ----- | ----- |\n",
    "|  C1   | 6 | (5,5) | 1 | 0 |\n",
    "|  S2   | 6 | (2,2) | 2 | 0 |\n",
    "|  C3   | 16 | (5,5) | 1 | 0 |\n",
    "|  S4   | 16 | (2,2) | 2 | 0 |\n",
    "|  C5   | 120 | (5,5) | 1 | 0 |\n",
    "|  F6   | 84 | --- | --- | --- |\n",
    "|  OUTPUT   | 10 | --- | --- | --- |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7QzRFAkSno3-"
   },
   "source": [
    "## 1. 각 층 별 출력 층의 크기 계산하기\n",
    "----\n",
    "\n",
    "출력층은 아래의 수식을 따릅니다.<br>\n",
    "$\n",
    "n_h^{[l]} = \\lfloor \\frac{n_h^{[l-1]}+2p^{[l]}-f_h^{[l]}}{s^{[l]}}+1\\rfloor\n",
    "$<br>\n",
    "$\n",
    "n_w^{[l]} = \\lfloor \\frac{n_w^{[l-1]}+2p^{[l]}-f_h^{[l]}}{s^{[l]}}+1\\rfloor\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AlsyzaDWno3_"
   },
   "source": [
    "#### 예제) 각 층 별 출력 층의 크기 계산하기 \n",
    "\n",
    "| Layer | FEATURE MAP SIZE |\n",
    "| ----- | -------   | \n",
    "| INPUT | (32,32,1) |\n",
    "|  C1   | ? |\n",
    "|  S2   | ? |\n",
    "|  C3   | ? |\n",
    "|  S4   | ? |\n",
    "|  C5   | ? |\n",
    "|  F6   | ? |\n",
    "|OUTPUT | ? |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4xS2lCgano3_"
   },
   "source": [
    "#### 정답 :\n",
    "\n",
    "| Layer | FEATURE MAP SIZE |\n",
    "| ----- | -------   | \n",
    "| INPUT | (32,32,1) |\n",
    "|  C1   | (28,28,6) |\n",
    "|  S2   | (14,14,6) |\n",
    "|  C3   | (10,10,16) |\n",
    "|  S4   | (5,5,16) |\n",
    "|  C5   | (1,1,120)|\n",
    "|  F6   | (84,) |\n",
    "|  OUTPUT   | (10,) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tC8f_b3kno4A"
   },
   "source": [
    "## 2. 각 층 별 파라미터의 수 계산하기\n",
    "----\n",
    "\n",
    "각 합성곱 층은 Filter 내 Weight와 Bias로 이루어져 있습니다.<br>\n",
    "$\n",
    "\\mbox{#parameter} = \\mbox{#weights} + \\mbox{#bias} \\\\\n",
    "\\mbox{#weights} = f_h^{[l]} * f_w^{[l]} * n_c^{l-1} * k^{[l]} \\\\\n",
    "\\mbox{#bias} = n_c^{[l]}\n",
    "$<br>\n",
    "풀링층은 별도로 학습하는 파라미터가 없습니다.\n",
    "\n",
    "#### Caution\n",
    "* sub-sampling은 Max-Pooling으로 생각하고 계산해 주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DU0xq8NEno4B"
   },
   "source": [
    "#### 예제) 각 층 별 출력 층의 크기 계산하기 \n",
    "\n",
    "| Layer | # Parameter |\n",
    "| ----- | -------   | \n",
    "| INPUT | 0 |\n",
    "|  C1   | $(5*5*1*6) + 6 = 156 $ |\n",
    "|  S2   | ? |\n",
    "|  C3   | ? |\n",
    "|  S4   | ? |\n",
    "|  C5   | ? |\n",
    "|  F6   | ? |\n",
    "|OUTPUT | ?|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yGwBZtsEno4B"
   },
   "source": [
    "#### 정답 :\n",
    "\n",
    "| Layer | # Parameter |\n",
    "| ----- | -------   | \n",
    "| INPUT | 0 |\n",
    "|  C1   | $(5*5*1*6) + 6 = 156 $ |\n",
    "|  S2   | $0$ |\n",
    "|  C3   | $(5*5*6*16) + 16 = 2,416 $ |\n",
    "|  S4   | $0$ |\n",
    "|  C5   | $(5*5*16*120)+120 = 48,120$ |\n",
    "|  F6   | $120*84 + 84 = 10,164 $ |\n",
    "|OUTPUT | $84*10 + 10 = 850$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vhdlsrmqxQ1t"
   },
   "source": [
    "# \\[ 3.간단한 Convolution Neural Network 만들기 \\]\n",
    "\n",
    "----\n",
    "----\n",
    " \n",
    "> *자신만의 Convolution Neural Network 을 생성해보고 결과를 확인해 봅니다.*<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "sfj0fizJvrFU",
    "outputId": "77d309b7-87eb-4585-a335-896105a313fb"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Reshape, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf \n",
    "\n",
    "\n",
    "# Parse images and labels\n",
    "(images_train, labels_train) = data_train\n",
    "(images_test, labels_test) = data_test\n",
    "images_train = images_train/255.\n",
    "images_test = images_test/255.\n",
    "labels_train = to_categorical(labels_train, 10)\n",
    "labels_test = to_categorical(labels_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtfy0Chnxi8u"
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(28,28))\n",
    "res_inputs = Reshape((28, 28, 1))(inputs)\n",
    "\n",
    "# layer 1 \n",
    "conv_1 = Conv2D(6, 5, 1, 'same', activation='relu')(res_inputs)\n",
    "mxpl_1 = MaxPooling2D(2, 2,'valid')(conv_1)\n",
    "\n",
    "#layer 2\n",
    "conv_2 = Conv2D(16, 5, 1, 'same',activation='relu')(mxpl_1)\n",
    "mxpl_2 = MaxPooling2D(2, 2,'valid')(conv_2)\n",
    "\n",
    "# layer 3 \n",
    "conv_3 = Conv2D(120, 5, 1, 'same',activation='relu')(mxpl_2)\n",
    "mxpl_3 = MaxPooling2D(2, 2,'valid')(conv_3)\n",
    "\n",
    "\n",
    "# FC Layer \n",
    "\n",
    "flat_conv = Flatten()(mxpl_3)\n",
    "fc1 = Dense(120, activation='relu', kernel_initializer='he_normal')(flat_conv)\n",
    "logits = Dense(10, activation='softmax', kernel_initializer='glorot_normal')(fc1)\n",
    "\n",
    "\n",
    "# Model \n",
    "model = Model(inputs, logits)\n",
    "model.compile('adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pA9gS-Kl0dsT"
   },
   "outputs": [],
   "source": [
    "model.fit(x=images_train, y=labels_train, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc =  = model.evaluate(x=images_test, y=labels_test, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NZCsX4Cjno4C"
   },
   "source": [
    "---\n",
    "⊙ Copyright(c) 2020 by PublicAI. All rights reserved <br>\n",
    "All pictures, codes, writings cannot be copied without permission. <br>\n",
    "Writen by PAI(info@publicai.co.kr) <br>\n",
    "last updated on 2020/01/4 <br>\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "4_합성곱 신경망의 층.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
