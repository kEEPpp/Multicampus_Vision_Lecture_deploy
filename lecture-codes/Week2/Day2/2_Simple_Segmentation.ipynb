{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><b>Public AI</b></i>\n",
    "<br>\n",
    "###  &nbsp;&nbsp; **✎&nbsp;&nbsp;Week 2. Semantic Segmentation**\n",
    "# Section 2. Simple Segmentation \n",
    "\n",
    "\n",
    "### _Objective_\n",
    "1. Semantic Segmentation 을 CNN 을 이용해 구현하는 가장 기본적인 원리를 이해하고 구현합니다. \n",
    "2. **Fashion MNIST Segmentation 만들기** : Keras를 활용하여 간단한 Simple Semantic Segmentation 모델을 구성해 보도록 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If You use in Colab, You Should run this script\n",
    "import os\n",
    "if (not os.path.exists(\"./multicampus_segmentation_generator\") and\n",
    "    not \"multicampus_segmentation_generator\" in os.getcwd()):\n",
    "    !git clone https://github.com/public-ai/multicampus_segmentation_generator.git\n",
    "    os.chdir(\"./multicampus_segmentation_generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Conv2D, MaxPool2D, Conv2DTranspose, ZeroPadding2D\n",
    "from tensorflow.keras.layers import Input, UpSampling2D, BatchNormalization, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import Softmax, Add\n",
    "from tensorflow.keras.layers import Lambda, concatenate\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow.keras.backend as K \n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "from generator import fasion_mnist_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1. Segmentation 을 위한 Fashion MNIST Dataset 생성하기 \n",
    "\n",
    "28 x 28 Pixel 로 이루어진 Fashion Mnist Image 이용해 Segmentation 데이터 셋을 생성합니다. <br>\n",
    "\n",
    "\n",
    "데이터셋 입력 데이터의 shape 는 128 x 128 로 기본 설정 되어 있으며 <br>\n",
    "또한 기존의 흑백 이미지 객체에 색을 입혀 3차원 이미지로 변경했습니다.  \n",
    "입력 데이터셋의 Shape 는 (128, 128, 3) 입니다.\n",
    "\n",
    "결과(y)의 Shape 는 (128, 128, 11) 입니다.\n",
    "11은 기존의 클래스 갯수(10) 에 배경 정보 까지 더한 결과 입니다. \n",
    "\n",
    "\n",
    "\n",
    "![Imgur](https://i.imgur.com/x3FIAtC.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = fasion_mnist_generator(1000, 10)\n",
    "print('Train Image shape : ', train_images.shape)\n",
    "print('Train Labels shape : ', train_labels.shape)\n",
    "print('Test Image shape : ', test_images.shape)\n",
    "print('Test Labels shape : ', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ Show Sample Images ] \n",
    "\n",
    "생성된 Segmentation Mnist Image 5개의 정답 이미지를 시각화 해봅니다. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_ind in range(5):\n",
    "    fig, axes = plt.subplots(1,12)\n",
    "    fig.set_size_inches((30,10))\n",
    "    sample_image = train_images[img_ind]\n",
    "    axes[0].imshow(train_images[img_ind])\n",
    "    axes[0].set_title('Image {}'.format(img_ind))\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    for i in range(1,12):\n",
    "        sample_mask = train_labels[img_ind][..., i-1]\n",
    "        axes[i].imshow(sample_mask)\n",
    "        axes[i].set_title('{}'.format(i))\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "un-atmTAHj6I"
   },
   "source": [
    "# 2. Semantic Segmentation 이해하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imgur](https://i.imgur.com/H3jkXlN.png)\n",
    "\n",
    "- **Classification** : Image 을 넣어서 해당 이미지가 어떤 숫자인지를 분류 해야 합니다..  \n",
    "\n",
    "- **Semantic Segmentation** : Image 을 넣어서 각 이미지 픽셀이 어떤 Class 인지 결정 해야 합니다..<br> \n",
    "마지막 logits 출력층의 크기는 class 갯수 + 배경 class 입니다. 즉 이번 예제에서는 10 + 1 임으로 \n",
    "출력층의 Shape 는 (None, **11**) 입니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Simple Segmentation 구현하기\n",
    "![Imgur](https://i.imgur.com/AoM6XiM.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F_NbL4_yr0dJ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Conv2D, Conv2DTranspose, MaxPool2D, Input, Add\n",
    "from tensorflow.python.keras.models import Model\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "# fix me! # input과 class 갯수 n_classes를 설정해주세요\n",
    "\n",
    "# Build Models\n",
    "# Block 1, Image shape (128, 128) -> (128, 128)\n",
    "# fix me! # 위 표에 만족하는 Convolution Neural Network를 구성해주세요\n",
    "\n",
    "# Block 2 Output Shape : (128, 128) -> (128, 128)\n",
    "# fix me! # 위 표에 만족하는 Convolution Neural Network를 구성해주세요\n",
    "\n",
    "# Block 3 Output Shape :(128, 128) -> (128, 128)\n",
    "# fix me! # 위 표에 만족하는 Convolution Neural Network를 구성해주세요\n",
    "\n",
    "# Get Logits : 마지막 출력에는 각 pixel 별로 배경을 포함해 각 클래스를 Classification 합니다\n",
    "# fix me! # 마지막 출력 layer를 구성하고 model을 생성해주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KgcuQAr7szMZ"
   },
   "outputs": [],
   "source": [
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6h-NVaM1s6dl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimizer, loss function, metric을 지정하는 compile 과정을 진행해주세요!\n",
    "# optimizer 로는 Nesterov Accelerated Gradient(NAG)를 사용해주세요\n",
    "# learning_rate=0.01, decay=1e-6, momentum=0.9\n",
    "# fix me!\n",
    "\n",
    "# batch_size는 1, epochs=1로 설정하여 학습을 진행해주세요!\n",
    "# fix me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ozgLSeVdHOCn"
   },
   "outputs": [],
   "source": [
    "test_loss, test_mean_iou = model.evaluate(test_images/255., test_labels)\n",
    "test_preds = model.predict(test_images/255.)\n",
    "test_cls = np.argmax(test_preds, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBCBCN6ns901"
   },
   "source": [
    "## Show Test Result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for img_id in range(len(test_cls)):\n",
    "    fig, axes = plt.subplots(1, 11)\n",
    "    fig.set_size_inches((30,10))\n",
    "    axes = np.array(axes).ravel()\n",
    "    for i in range(11):\n",
    "        axes[i].axis('off')\n",
    "        axes[i].imshow(test_cls[img_id] == i)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "⊙ Copyright(c) 2020 by PublicAI. All rights reserved <br>\n",
    "All pictures, codes, writings cannot be copied without permission. <br>\n",
    "Writen by PAI(info@publicai.co.kr) <br>\n",
    "last updated on 2020/01/4 <br>\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Simple_Segmentation.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
